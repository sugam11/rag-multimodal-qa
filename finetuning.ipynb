{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e37fd8-9ccd-43b2-a416-a8b61f89c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loaders import data_utils\n",
    "act_data = data_utils.load_jsonl_file(\"/data/users/sgarg6/capstone/multimodalqa/MMQA_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d952ff-c54c-4866-a345-da08786e87b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 218285 text passages\n",
      "Loaded 57058 image sources\n"
     ]
    }
   ],
   "source": [
    "from data_loaders.dataset_mmqa import MMQAKnowledgeBase\n",
    "mmqa_kb = MMQAKnowledgeBase(\n",
    "        \"/data/users/sgarg6/capstone/multimodalqa/MMQA_texts.jsonl\",\n",
    "        \"/data/users/sgarg6/capstone/multimodalqa/MMQA_images.jsonl\",\n",
    "        \"/data/users/sgarg6/capstone/multimodalqa/final_dataset_images\"\n",
    "    )\n",
    "mmqa_text = [text for text in mmqa_kb.get_all_texts()]\n",
    "mmqa_img = [img for img in mmqa_kb.get_all_images()]\n",
    "\n",
    "mmqa_map = {text[\"id\"]: text for text in mmqa_text}\n",
    "mmqa_map_img = {img[\"id\"]: img for img in mmqa_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e02bec4-9fc8-450f-bdf2-774816711728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Hillaryland',\n",
       " 'url': 'https://en.wikipedia.org/wiki/Hillaryland',\n",
       " 'id': 'a7d9e6350bafc46b700e4d0739a39594',\n",
       " 'text': 'Hillaryland was the self-designated name of a group of core advisors to Hillary Clinton, when she was First Lady of the United States and again when, as United States Senator, she was one of the Democratic Party candidates for President in the 2008 U.S. election.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmqa_map['a7d9e6350bafc46b700e4d0739a39594']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11f68e1-fc83-4241-ac78-f2a40af81b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "blank_image = Image.open(\"resources/1x1_#00000000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3c52e2-3719-412b-ad4e-9006fd8710ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for ques in act_data:\n",
    "    ques_type = ques[\"answers\"][0][\"modality\"]\n",
    "    if \"table\" in ques_type:\n",
    "        continue\n",
    "    question = ques[\"question\"]\n",
    "    #try:\n",
    "    \n",
    "    if len(ques[\"answers\"][0][\"text_instances\"]) > 0:\n",
    "        passage = mmqa_map[ques[\"answers\"][0][\"text_instances\"][0][\"doc_id\"]][\"text\"]\n",
    "    else:\n",
    "        passage = \"\"\n",
    "    if len(ques[\"answers\"][0][\"image_instances\"]) > 0:\n",
    "        image = mmqa_map_img[ques[\"answers\"][0][\"image_instances\"][0][\"doc_id\"]][\"path\"]\n",
    "    else:\n",
    "        image = blank_image\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     print(ques)\n",
    "    #     break\n",
    "    ans = ques[\"answers\"][0][\"answer\"]\n",
    "    prompt = f\"You are a helpful Question Answering assistant. You are being provided with images and passages, a question about the image or the passage and an answer. Answer the question using either the image or the passage. <image> Passage: {passage} Question: {question}. Answer: {ans}<|endofchunk|>\"\n",
    "    train_data.append((prompt, ques_type, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fefea1-1e02-439a-a0d1-6dca7c079d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6779d95-738a-4aa8-9a6b-5482b9ec73e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23817"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(act_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d01bd98-c65f-449a-b46d-0210bf292e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"You are a helpful Question Answering assistant. You are being provided with images and passages, a question about the image or the passage and an answer. Answer the question using either the image or the passage. <image> Passage: The Game Boy Advance (Japanese: ゲームボーイアドバンス, Hepburn: Gēmu Bōi Adobansu) (GBA) is a 32-bit handheld video game console developed, manufactured and marketed by Nintendo as the successor to the Game Boy Color. It was released in Japan on March 21, 2001, in North America on June 11, 2001, in Australia and Europe on June 22, 2001, and in mainland China on June 8, 2004 (iQue Player). Nintendo's competitors in the handheld market at the time were the Neo Geo Pocket Color, WonderSwan, GP32, Tapwave Zodiac, and the N-Gage. Despite the competitors' best efforts, Nintendo maintained a majority market share with the Game Boy Advance. Question: When did the virtual console system when Japan had 102 games come out?. Answer: March 21, 2001<|endofchunk|>\",\n",
       " 'text',\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1x1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1afb33d-a32e-4f87-9d44-bb817fe0d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MMQADataset(Dataset):\n",
    "    def __init__(self, train_data):\n",
    "        self.train_data = train_data\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.train_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5918b646-a0da-4882-a604-9b5e313d8fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "/data/users/sgarg6/hf_models/modules/transformers_modules/anas-awadalla/mpt-1b-redpajama-200b-dolly/f0a13e41fcee2217cd701219ffa1eaef7fe955ea/attention.py:289: UserWarning: Using `attn_impl: torch`. If your model does not use `alibi` or `prefix_lm` we recommend using `attn_impl: flash` otherwise we recommend using `attn_impl: triton`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n",
      "Flamingo model initialized with 1046992944 trainable parameters\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import flamingo_model\n",
    "model = flamingo_model.FlamingoModel(\"anas-awadalla/mpt-1b-redpajama-200b-dolly\",\n",
    "                                     \"anas-awadalla/mpt-1b-redpajama-200b-dolly\",\n",
    "                                     1, \n",
    "                                    \"openflamingo/OpenFlamingo-3B-vitl-mpt1b-langinstruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a000b7-65e9-4e0d-8051-f49a2c0cba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    prompt = [item[0] for item in batch]\n",
    "    ques_type = [item[1] for item in batch]\n",
    "    images = [item[2] for item in batch]\n",
    "    model.tokenizer.padding_side = \"right\"\n",
    "    prompt = [f\"{s.strip()}{model.tokenizer.eos_token}\" for s in prompt]\n",
    "    prmpt_tokens = model.tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    images = [mmqa_kb.get_image(image) if ques_type[idx] == \"image\" else image for idx, image in enumerate(images)]\n",
    "    images = model.process_imgs(images)\n",
    "    images = images.unsqueeze(1)\n",
    "    return prmpt_tokens, ques_type, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eda05b-6eb3-4b33-9b89-f836c0507572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.920361042022705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [01:53,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9892937496988596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1002it [03:49,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9173681898550554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [05:42,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8653798380309465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1863it [07:05,  3.74it/s]/soe/sgarg6/conda/envs/capstone/lib/python3.10/site-packages/PIL/Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "2001it [07:36,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8457386346384026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [09:31,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8298833826061536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [11:25,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.819169101472578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3502it [13:19,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8107281055187574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [15:13,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8053132040564401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4502it [17:08,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7970049100977874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [19:02,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7945326890105893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5502it [20:56,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7938888501121963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [22:49,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7892400637812822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6322it [24:00,  5.10it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "train_data = MMQADataset(train_data)\n",
    "data_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "optimizer = torch.optim.Adam(model.model.parameters(), 0.001)\n",
    "running_loss = 0\n",
    "loss_log = []\n",
    "model.model.train()\n",
    "\n",
    "for i, batch in tqdm(enumerate(data_loader)):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    input_ids = batch[0][\"input_ids\"]\n",
    "    labels = input_ids.clone()\n",
    "    labels[labels == model.tokenizer.pad_token_id] = -100\n",
    "    labels[labels == model.tokenizer.eos_token] = -100\n",
    "    labels = labels.to(model.device)\n",
    "    # Forward + backward + optimize\n",
    "    loss = model.model(\n",
    "            vision_x=batch[2].to(model.device),\n",
    "            lang_x=batch[0][\"input_ids\"].to(model.device),\n",
    "            attention_mask=batch[0][\"attention_mask\"].to(model.device),\n",
    "            labels=labels,\n",
    "        )[0]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_log.append(loss.item())\n",
    "    # Print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 500 == 0:\n",
    "        print(running_loss/(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3fb3d-db04-4e4b-a482-1d6dc59b67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), \"/data/users/sgarg6/capstone/models/3b_finetune/model_eoc_no_eol.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac23515-083d-4482-81b1-1556ee0bff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d23ff-b4d4-4b33-9fba-e281115ca0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
